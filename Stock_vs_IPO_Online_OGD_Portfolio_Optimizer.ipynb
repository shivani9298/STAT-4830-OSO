{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Market vs IPOs — Online Portfolio Optimizer (OGD)\n",
    "\n",
    "This notebook is a **focused extension** of the Week 11 Online Gradient Descent portfolio optimizer.\n",
    "It shows how to build a *two-sleeve* allocator between:\n",
    "- **Stock market** (e.g., SPY / total market index)\n",
    "- **IPO sleeve** (either an IPO ETF like `IPO`, or a custom IPO basket built from IPO-level data)\n",
    "\n",
    "The optimizer runs **online** (walk-forward): at each date *t*, it updates weights using only a trailing window of past returns.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "# Reproducibility (optional)\n",
    "np.random.seed(7)\n",
    "torch.manual_seed(7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Data inputs\n",
    "\n",
    "You need a return series for the **market sleeve** and the **IPO sleeve**.\n",
    "\n",
    "Supported options below:\n",
    "1. **CSV with returns** (recommended for reproducibility)\n",
    "2. **Yahoo Finance via yfinance** (if you have internet access)\n",
    "3. **Custom IPO basket** from panel data (ticker-level returns + IPO date)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_returns_from_csv(path, date_col=\"date\"):\n",
    "    \"\"\"Load a CSV containing date + return columns.\n",
    "    Expected columns (example): date, market_ret, ipo_ret\n",
    "    Returns a DataFrame indexed by date with float returns.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "    df = df.set_index(date_col).sort_index()\n",
    "    # Keep only numeric return columns\n",
    "    ret = df.select_dtypes(include=[np.number]).copy()\n",
    "    return ret\n",
    "\n",
    "def load_returns_with_yfinance(tickers, start=\"2015-01-01\", end=None):\n",
    "    \"\"\"Fetch adjusted close from Yahoo Finance and convert to daily returns.\n",
    "    Requires: pip install yfinance\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import yfinance as yf\n",
    "    except Exception as e:\n",
    "        raise ImportError(\"yfinance not installed. Run: pip install yfinance\") from e\n",
    "\n",
    "    px = yf.download(tickers, start=start, end=end, auto_adjust=True, progress=False)[\"Close\"]\n",
    "    if isinstance(px, pd.Series):\n",
    "        px = px.to_frame()\n",
    "    px = px.dropna(how=\"all\")\n",
    "    rets = px.pct_change().dropna()\n",
    "    rets.columns = list(tickers)\n",
    "    return rets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Build an IPO basket from panel data (optional)\n",
    "\n",
    "If you have IPO-level data (e.g., from CRSP/Compustat, Refinitiv, etc.), you can build an IPO sleeve by:\n",
    "- selecting stocks within *N* trading days since IPO (e.g., first 252 days)\n",
    "- equal-weighting (or value-weighting) those names each day\n",
    "\n",
    "Input panel schema:\n",
    "- `date` (daily)\n",
    "- `ticker`\n",
    "- `ret` (daily return)\n",
    "- `ipo_date` (first trading date)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def build_ipo_basket_returns(panel: pd.DataFrame,\n",
    "                             holding_days: int = 252,\n",
    "                             min_names: int = 10) -> pd.Series:\n",
    "    \"\"\"Create an equal-weight IPO basket from a panel.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    panel : DataFrame\n",
    "        Columns: date, ticker, ret, ipo_date\n",
    "    holding_days : int\n",
    "        Include tickers from IPO date up to this many trading days after IPO.\n",
    "    min_names : int\n",
    "        If fewer than this many IPO names are available on a day, basket return is NaN.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Series indexed by date: ipo_basket_ret\n",
    "    \"\"\"\n",
    "    req = {\"date\", \"ticker\", \"ret\", \"ipo_date\"}\n",
    "    missing = req - set(panel.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"panel is missing columns: {sorted(missing)}\")\n",
    "\n",
    "    df = panel.copy()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df[\"ipo_date\"] = pd.to_datetime(df[\"ipo_date\"])\n",
    "    df = df.sort_values([\"date\", \"ticker\"])\n",
    "\n",
    "    # Trading-day age approximation: rank dates within each ticker\n",
    "    df[\"age\"] = df.groupby(\"ticker\")[\"date\"].rank(method=\"first\").astype(int) - 1\n",
    "\n",
    "    # Keep only first `holding_days` trading days post-IPO\n",
    "    df = df[(df[\"age\"] >= 0) & (df[\"age\"] < holding_days)]\n",
    "\n",
    "    # Equal-weight each day\n",
    "    g = df.groupby(\"date\")\n",
    "    counts = g[\"ret\"].count()\n",
    "    basket = g[\"ret\"].mean()\n",
    "\n",
    "    basket[counts < min_names] = np.nan\n",
    "    basket.name = \"ipo_ret\"\n",
    "    return basket\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Convert returns to a price index (for drawdown)\n",
    "\n",
    "The optimizer below operates on **returns**, but some diagnostics (like drawdown) are easiest on a price index.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def returns_to_price_index(returns: pd.DataFrame, start_value: float = 100.0) -> pd.DataFrame:\n",
    "    px = (1.0 + returns.fillna(0.0)).cumprod() * start_value\n",
    "    return px\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Online Gradient Descent allocator\n",
    "\n",
    "Objective (maximized on a trailing window):\n",
    "- mean portfolio return\n",
    "- minus risk penalty (variance)\n",
    "- minus max drawdown penalty\n",
    "- minus turnover penalty (L1 distance from previous weights)\n",
    "\n",
    "Constraints:\n",
    "- long-only\n",
    "- weights sum to 1 (simplex projection)\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "def project_to_simplex(v: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Euclidean projection onto the probability simplex.\"\"\"\n",
    "    if v.ndim != 1:\n",
    "        raise ValueError(\"v must be a 1D tensor\")\n",
    "    n = v.numel()\n",
    "    # Sort descending\n",
    "    u, _ = torch.sort(v, descending=True)\n",
    "    cssv = torch.cumsum(u, dim=0) - 1\n",
    "    ind = torch.arange(1, n + 1, device=v.device, dtype=v.dtype)\n",
    "    cond = u - cssv / ind > 0\n",
    "    if not torch.any(cond):\n",
    "        return torch.ones_like(v) / n\n",
    "    rho = torch.nonzero(cond, as_tuple=False)[-1].item()\n",
    "    theta = cssv[rho] / (rho + 1.0)\n",
    "    w = torch.clamp(v - theta, min=0.0)\n",
    "    # Numerical stability: renormalize\n",
    "    s = w.sum()\n",
    "    return w / s if s > 0 else torch.ones_like(v) / n\n",
    "\n",
    "def max_drawdown_from_returns(port_ret: torch.Tensor, eps: float = 1e-8) -> torch.Tensor:\n",
    "    \"\"\"Differentiable-ish max drawdown based on cumulative product.\"\"\"\n",
    "    cum = torch.cumprod(1.0 + port_ret, dim=0)\n",
    "    peak, _ = torch.cummax(cum, dim=0)\n",
    "    dd = cum / (peak + eps) - 1.0\n",
    "    return torch.min(dd)  # negative number (e.g., -0.25)\n",
    "\n",
    "class OnlineOGDAllocator:\n",
    "    def __init__(self,\n",
    "                 n_assets: int,\n",
    "                 window: int = 252,\n",
    "                 lr: float = 0.10,\n",
    "                 lr_decay: float = 0.999,\n",
    "                 risk_aversion: float = 10.0,\n",
    "                 drawdown_penalty: float = 5.0,\n",
    "                 turnover_penalty: float = 0.25,\n",
    "                 device: str = \"cpu\"):\n",
    "\n",
    "        self.n_assets = n_assets\n",
    "        self.window = int(window)\n",
    "        self.lr0 = float(lr)\n",
    "        self.lr_decay = float(lr_decay)\n",
    "        self.risk_aversion = float(risk_aversion)\n",
    "        self.drawdown_penalty = float(drawdown_penalty)\n",
    "        self.turnover_penalty = float(turnover_penalty)\n",
    "        self.device = device\n",
    "\n",
    "        self.t = 0\n",
    "        self.w = torch.ones(n_assets, device=device) / n_assets\n",
    "        self.w_prev = self.w.clone()\n",
    "\n",
    "    def step(self, window_returns: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Update weights using trailing window returns (T x n_assets).\"\"\"\n",
    "        self.t += 1\n",
    "        lr = self.lr0 * (self.lr_decay ** (self.t - 1))\n",
    "\n",
    "        R = torch.tensor(window_returns, device=self.device)\n",
    "        # Decision variable\n",
    "        w_var = self.w.clone().detach().requires_grad_(True)\n",
    "\n",
    "        port = R @ w_var  # (T,)\n",
    "        mu = port.mean()\n",
    "        var = port.var(unbiased=False)\n",
    "\n",
    "        mdd = max_drawdown_from_returns(port)\n",
    "        turnover = torch.sum(torch.abs(w_var - self.w_prev))\n",
    "\n",
    "        # maximize utility => minimize negative utility\n",
    "        utility = mu - self.risk_aversion * var + self.drawdown_penalty * mdd - self.turnover_penalty * turnover\n",
    "        loss = -utility\n",
    "        loss.backward()\n",
    "\n",
    "        grad = w_var.grad.detach()\n",
    "\n",
    "        # Gradient ascent step (since maximizing utility)\n",
    "        w_new = self.w + lr * (-grad) * 0.0  # placeholder\n",
    "\n",
    "        # We used loss = -utility, so grad(loss)= -grad(utility)\n",
    "        # To ascend utility: w <- w + lr * grad(utility) = w - lr * grad(loss)\n",
    "        w_new = self.w - lr * grad\n",
    "\n",
    "        w_new = project_to_simplex(w_new)\n",
    "        self.w_prev = self.w.clone()\n",
    "        self.w = w_new.detach()\n",
    "        return self.w.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Example (synthetic data)\n",
    "\n",
    "This section runs end-to-end without external data. Replace it with your own market + IPO returns.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Synthetic daily returns: market is smoother; IPO sleeve has higher vol and occasional big swings\n",
    "n_days = 1500\n",
    "dates = pd.bdate_range(\"2019-01-01\", periods=n_days)\n",
    "\n",
    "market = np.random.normal(loc=0.00035, scale=0.010, size=n_days)\n",
    "ipo = np.random.normal(loc=0.00050, scale=0.020, size=n_days)\n",
    "\n",
    "# Add occasional IPO crash / pop days\n",
    "shock_idx = np.random.choice(np.arange(n_days), size=20, replace=False)\n",
    "ipo[shock_idx] += np.random.normal(loc=0.0, scale=0.10, size=len(shock_idx))\n",
    "\n",
    "rets = pd.DataFrame({\"MARKET\": market, \"IPO\": ipo}, index=dates).dropna()\n",
    "rets.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Walk-forward optimization\n",
    "window = 252\n",
    "alloc = OnlineOGDAllocator(n_assets=rets.shape[1],\n",
    "                          window=window,\n",
    "                          lr=0.15,\n",
    "                          lr_decay=0.999,\n",
    "                          risk_aversion=25.0,\n",
    "                          drawdown_penalty=5.0,\n",
    "                          turnover_penalty=0.10)\n",
    "\n",
    "weights = []\n",
    "out_dates = []\n",
    "\n",
    "for i in range(window, len(rets)):\n",
    "    w = alloc.step(rets.iloc[i-window:i].values)\n",
    "    weights.append(w)\n",
    "    out_dates.append(rets.index[i])\n",
    "\n",
    "w_df = pd.DataFrame(weights, index=out_dates, columns=rets.columns)\n",
    "w_df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Portfolio backtest (apply weights one-day-ahead to avoid lookahead)\n",
    "aligned_rets = rets.loc[w_df.index]\n",
    "port_ret = (aligned_rets.values * w_df.values).sum(axis=1)\n",
    "port_ret = pd.Series(port_ret, index=w_df.index, name=\"PORT\")\n",
    "\n",
    "eqw_ret = aligned_rets.mean(axis=1)\n",
    "mkt_ret = aligned_rets[\"MARKET\"]\n",
    "\n",
    "cum = (1 + pd.concat([port_ret, eqw_ret.rename(\"EQW\"), mkt_ret.rename(\"MARKET\")], axis=1)).cumprod()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(cum.index, cum[\"PORT\"], label=\"OGD Portfolio\")\n",
    "plt.plot(cum.index, cum[\"EQW\"], label=\"Equal Weight\")\n",
    "plt.plot(cum.index, cum[\"MARKET\"], label=\"Market Only\")\n",
    "plt.legend()\n",
    "plt.title(\"Cumulative Return (synthetic example)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Growth of $1\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(w_df.index, w_df[\"MARKET\"], label=\"Weight: MARKET\")\n",
    "plt.plot(w_df.index, w_df[\"IPO\"], label=\"Weight: IPO\")\n",
    "plt.legend()\n",
    "plt.title(\"Portfolio Weights Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Weight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Swap in real data\n",
    "\n",
    "### Option A — use ETF proxies\n",
    "If you can use internet access, common proxies are:\n",
    "- Market: `SPY` (S&P 500) or `VTI` (total market)\n",
    "- IPO sleeve: `IPO` (Renaissance IPO ETF)\n",
    "\n",
    "### Option B — build an IPO sleeve from IPO-level data\n",
    "Use `build_ipo_basket_returns(panel, ...)` to produce `ipo_ret`, then align it with market returns.\n",
    "\n",
    "Below are templates (commented out)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# --- Option A: yfinance (requires internet) ---\n",
    "# rets = load_returns_with_yfinance([\"SPY\", \"IPO\"], start=\"2015-01-01\")\n",
    "# rets.columns = [\"MARKET\", \"IPO\"]\n",
    "# rets = rets.dropna()\n",
    "\n",
    "# --- Option B: CSV with returns ---\n",
    "# rets = load_returns_from_csv(\"/path/to/market_ipo_returns.csv\")\n",
    "# rets = rets.rename(columns={\"market_ret\":\"MARKET\", \"ipo_ret\":\"IPO\"}).dropna()\n",
    "\n",
    "# --- Option C: panel -> IPO basket ---\n",
    "# panel = pd.read_csv(\"/path/to/ipo_panel.csv\")  # date,ticker,ret,ipo_date\n",
    "# ipo_ret = build_ipo_basket_returns(panel, holding_days=252, min_names=10)\n",
    "# market_ret = load_returns_with_yfinance([\"SPY\"], start=\"2015-01-01\")[\"SPY\"]\n",
    "# rets = pd.concat([market_ret.rename(\"MARKET\"), ipo_ret.rename(\"IPO\")], axis=1).dropna()\n",
    "\n",
    "# After building `rets`, rerun the Walk-forward optimization cell.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
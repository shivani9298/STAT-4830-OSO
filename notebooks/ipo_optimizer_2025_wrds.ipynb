{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# IPO Portfolio Optimizer (WRDS)\n",
        "\n",
        "Runs the GRU allocator on IPO data from **SDC New Deals** (all rows where ipodate is not null) + **Compustat** (daily open/close). Market data and shares from WRDS. SDC is the sole IPO source; no CSV fallback."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-20T15:38:34.701947Z",
          "iopub.status.busy": "2026-02-20T15:38:34.700937Z",
          "iopub.status.idle": "2026-02-20T15:38:40.281550Z",
          "shell.execute_reply": "2026-02-20T15:38:40.281550Z"
        }
      },
      "source": [
        "# Imports and path setup\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
        "sys.path.insert(0, str(ROOT))\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "from src.wrds_data import get_connection, load_market_returns_wrds\n",
        "from src.data_layer import align_returns, add_optional_features, build_rolling_windows, train_val_split\n",
        "from src.train import run_training\n",
        "from src.export import predict_weights, portfolio_stats, export_weights_csv, export_summary\n",
        "from src.policy_layer import ipo_tilt_to_position_scale, policy_rule"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-20T15:38:40.281550Z",
          "iopub.status.busy": "2026-02-20T15:38:40.281550Z",
          "iopub.status.idle": "2026-02-20T15:38:41.365564Z",
          "shell.execute_reply": "2026-02-20T15:38:41.364445Z"
        }
      },
      "source": [
        "# Connect to WRDS (set WRDS_USERNAME and WRDS_PASSWORD env vars for non-interactive)\n",
        "conn = get_connection()\n",
        "print(\"Connected to WRDS.\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading library list...\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "Done\n",
            "Connected to WRDS.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## IPO Data: SDC New Deals + Compustat\n",
        "\n",
        "IPO tickers come from **SDC New Deals** (all rows where ipodate is not null); daily open/close prices come from **Compustat** (comp.sec_dprc). SDC schema is `sdc`, table `wrds_ni_details`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# IPO data: SDC New Deals (all rows where ipodate is not null) + Compustat\n",
        "from src.wrds_data import load_ipo_data_from_sdc_wrds\n",
        "\n",
        "ipo_csv = load_ipo_data_from_sdc_wrds(conn, start='2024-01-01', end='2025-12-31', library='sdc')\n",
        "print(f\"IPO data from SDC + Compustat: {len(ipo_csv)} rows, {ipo_csv['tic'].nunique()} tickers\")\n",
        "\n",
        "ipo_csv['datadate'] = pd.to_datetime(ipo_csv['datadate'])\n",
        "ipo_df = ipo_csv.groupby('tic').agg({'datadate': 'min'}).reset_index()\n",
        "ipo_df.columns = ['ticker', 'ipo_date']\n",
        "ipo_df = ipo_df.sort_values('ipo_date').reset_index(drop=True)\n",
        "\n",
        "prices_ipo = ipo_csv.pivot_table(index='datadate', columns='tic', values='prccd')\n",
        "prices_ipo.index = pd.to_datetime(prices_ipo.index).normalize()\n",
        "start_d = prices_ipo.index.min().strftime('%Y-%m-%d')\n",
        "end_d = prices_ipo.index.max().strftime('%Y-%m-%d')\n",
        "\n",
        "print(f\"IPO tickers: {len(ipo_df)}\")\n",
        "print(f\"Date range: {start_d} to {end_d}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-20T15:38:41.366569Z",
          "iopub.status.busy": "2026-02-20T15:38:41.366569Z",
          "iopub.status.idle": "2026-02-20T15:38:41.607145Z",
          "shell.execute_reply": "2026-02-20T15:38:41.607145Z"
        }
      },
      "source": [
        "# IPO data (ipo_csv, ipo_df, prices_ipo, start_d, end_d) loaded in previous cell"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IPO tickers: 379\n",
            "Date range: 2025-01-02 to 2025-12-31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-20T15:38:41.607145Z",
          "iopub.status.busy": "2026-02-20T15:38:41.607145Z",
          "iopub.status.idle": "2026-02-20T15:38:41.696378Z",
          "shell.execute_reply": "2026-02-20T15:38:41.696378Z"
        }
      },
      "source": [
        "# Custom market-cap weighted portfolio (replaces SPY) - Compustat, then CRSP, then CRSP index (no yfinance)\n",
        "PORTFOLIO_TICKERS = [\n",
        "    \"AAPL\", \"MSFT\", \"NVDA\", \"GOOGL\", \"AMZN\", \"META\", \"AVGO\", \"ORCL\", \"IBM\", \"CSCO\",\n",
        "    \"JPM\", \"V\", \"MA\", \"GS\", \"MS\", \"BAC\", \"C\", \"AXP\", \"SCHW\",\n",
        "    \"UNH\", \"JNJ\", \"LLY\", \"PFE\", \"MRNA\", \"BMY\", \"GILD\", \"CVS\", \"VRTX\", \"ISRG\",\n",
        "    \"WMT\", \"NKE\", \"PG\", \"TGT\", \"COST\", \"KO\", \"PEP\", \"MCD\", \"SBUX\", \"YUM\",\n",
        "    \"XOM\", \"CVX\", \"NEE\", \"DUK\", \"SO\", \"D\", \"ENB\", \"SLB\", \"EOG\", \"PSX\",\n",
        "    \"DE\", \"LMT\", \"RTX\", \"BA\", \"CAT\", \"GE\", \"HON\", \"UPS\", \"EMR\", \"NOC\",\n",
        "    \"PLD\", \"AMT\", \"EQIX\", \"O\", \"SPG\", \"VICI\", \"DLR\", \"WY\", \"EQR\", \"PSA\",\n",
        "    \"TSLA\", \"FDX\", \"GM\", \"F\", \"RIVN\", \"NIO\", \"CSX\", \"UNP\", \"DAL\",\n",
        "    \"TSM\", \"ASML\", \"AMD\", \"TXN\", \"INTC\", \"MU\", \"QCOM\", \"LRCX\", \"NXPI\", \"ADI\",\n",
        "    \"ADM\", \"BG\", \"CF\", \"TSN\", \"MOS\", \"FMC\", \"CAG\", \"SYY\", \"HRL\", \"MDLZ\",\n",
        "    \"NFLX\", \"DIS\", \"PARA\", \"WBD\", \"CMCSA\", \"SPOT\", \"LYV\", \"TTWO\", \"EA\",\n",
        "]\n",
        "from src.wrds_data import load_market_returns_wrds, load_portfolio_returns_compustat_wrds, load_portfolio_returns_value_weighted_wrds, load_stock_returns_wrds\n",
        "market_ret = load_portfolio_returns_compustat_wrds(conn, start=start_d, end=end_d, tickers=PORTFOLIO_TICKERS, value_weighted=True)\n",
        "if market_ret.empty or len(market_ret.dropna()) < 50:\n",
        "    portfolio_rets = load_stock_returns_wrds(conn, start=start_d, end=end_d, tickers=PORTFOLIO_TICKERS)\n",
        "    if portfolio_rets.empty or portfolio_rets.shape[1] < 5:\n",
        "        market_ret = load_market_returns_wrds(conn, start=start_d, end=end_d)\n",
        "        print(\"Using CRSP market index (crsp.dsi)\")\n",
        "    else:\n",
        "        market_ret = portfolio_rets.mean(axis=1).dropna()\n",
        "        market_ret.name = \"market_return\"\n",
        "        print(\"Using equal-weighted portfolio (CRSP)\")\n",
        "market_ret = market_ret.reindex(prices_ipo.index).dropna()\n",
        "if len(market_ret) < 50:\n",
        "    raise RuntimeError(\"Insufficient portfolio return data\")\n",
        "\n",
        "# Shares from comp.funda\n",
        "ipo_tickers = ipo_df['ticker'].tolist()\n",
        "gvkeys = ipo_csv[['tic', 'gvkey']].drop_duplicates()\n",
        "gvkey_list = \"','\".join(gvkeys['gvkey'].astype(str).str.zfill(6).unique().tolist())\n",
        "shares_df = conn.raw_sql(f\"\"\"\n",
        "    select gvkey, datadate, csho\n",
        "    from comp.funda\n",
        "    where gvkey in ('{gvkey_list}')\n",
        "        and datadate >= '2024-01-01'\n",
        "        and csho > 0\n",
        "        and indfmt = 'INDL' and datafmt = 'STD'\n",
        "\"\"\", date_cols=['datadate'])\n",
        "\n",
        "shares_outstanding = {}\n",
        "if len(shares_df) > 0:\n",
        "    last_csho = shares_df.sort_values('datadate').groupby('gvkey')['csho'].last()\n",
        "    gvkey_to_tic = dict(zip(gvkeys['gvkey'].astype(str).str.zfill(6), gvkeys['tic']))\n",
        "    for gvkey, csho in last_csho.items():\n",
        "        t = gvkey_to_tic.get(str(gvkey).zfill(6))\n",
        "        if t:\n",
        "            shares_outstanding[t] = float(csho) * 1000\n",
        "\n",
        "for t in ipo_tickers:\n",
        "    if t in prices_ipo.columns and t not in shares_outstanding:\n",
        "        p = prices_ipo[t].dropna()\n",
        "        if len(p) > 0 and p.iloc[-1] > 0:\n",
        "            shares_outstanding[t] = 1e6 / p.iloc[-1]\n",
        "\n",
        "prices = prices_ipo.copy().ffill().bfill()\n",
        "\n",
        "print(f\"Market return days: {len(market_ret)} (market-cap weighted)\")\n",
        "print(f\"Prices shape: {prices.shape}, Tickers with shares: {len(shares_outstanding)}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prices shape: (250, 380), Tickers with shares: 379\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-20T15:38:41.696378Z",
          "iopub.status.busy": "2026-02-20T15:38:41.696378Z",
          "iopub.status.idle": "2026-02-20T15:38:44.467272Z",
          "shell.execute_reply": "2026-02-20T15:38:44.466260Z"
        }
      },
      "source": [
        "# Build 180-day market-cap weighted IPO index\n",
        "def build_ipo_index_mcap(prices_df, ipo_dates_df, shares_dict, holding_days=180, min_names=1):\n",
        "    ipo_lookup = dict(zip(ipo_dates_df['ticker'], ipo_dates_df['ipo_date']))\n",
        "    returns_df = prices_df.pct_change()\n",
        "    trading_days = {t: prices_df[t].dropna().index.tolist() for t in prices_df.columns \n",
        "                    if t != 'SPY' and t in ipo_lookup}\n",
        "    all_dates = prices_df.index.tolist()\n",
        "    index_data = []\n",
        "    for date in all_dates:\n",
        "        market_caps = {}\n",
        "        for ticker, ipo_date in ipo_lookup.items():\n",
        "            if ticker not in trading_days or ticker not in shares_dict:\n",
        "                continue\n",
        "            ticker_days = trading_days[ticker]\n",
        "            first_trade_idx = next((i for i, d in enumerate(ticker_days) if d >= ipo_date), None)\n",
        "            if first_trade_idx is None:\n",
        "                continue\n",
        "            if date in ticker_days:\n",
        "                current_idx = ticker_days.index(date)\n",
        "                if 0 <= current_idx - first_trade_idx < holding_days:\n",
        "                    try:\n",
        "                        cp = prices_df.loc[date, ticker]\n",
        "                        if pd.notna(cp) and cp > 0:\n",
        "                            market_caps[ticker] = cp * shares_dict[ticker]\n",
        "                    except Exception:\n",
        "                        pass\n",
        "        total_mcap = sum(market_caps.values())\n",
        "        if len(market_caps) >= min_names and total_mcap > 0:\n",
        "            wr, vc = 0.0, 0\n",
        "            for t, mcap in market_caps.items():\n",
        "                try:\n",
        "                    r = returns_df.loc[date, t]\n",
        "                    if pd.notna(r):\n",
        "                        wr += (mcap / total_mcap) * r\n",
        "                        vc += 1\n",
        "                except Exception:\n",
        "                    pass\n",
        "            ipo_ret = wr if vc >= min_names else np.nan\n",
        "        else:\n",
        "            ipo_ret = np.nan\n",
        "        index_data.append({'date': date, 'ipo_ret': ipo_ret})\n",
        "    return pd.DataFrame(index_data).set_index('date')\n",
        "\n",
        "ipo_index = build_ipo_index_mcap(prices, ipo_df, shares_outstanding, holding_days=180)\n",
        "print(f\"IPO index: {ipo_index['ipo_ret'].notna().sum()} days with valid returns\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IPO index: 249 days with valid returns\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-20T15:38:44.467272Z",
          "iopub.status.busy": "2026-02-20T15:38:44.467272Z",
          "iopub.status.idle": "2026-02-20T15:38:44.494530Z",
          "shell.execute_reply": "2026-02-20T15:38:44.494530Z"
        }
      },
      "source": [
        "# Build data dict: market_return (custom portfolio), ipo_return\n",
        "ipo_ret = ipo_index['ipo_ret'].rename('ipo_return')\n",
        "\n",
        "df = align_returns(market_ret, ipo_ret)\n",
        "df = add_optional_features(df, include_vix=False)\n",
        "feature_cols = list(df.columns)\n",
        "\n",
        "WINDOW = 126  # ~6 months; 2025 has limited data\n",
        "X, R, dates = build_rolling_windows(df, window_len=WINDOW, feature_cols=feature_cols)\n",
        "X_train, R_train, d_train, X_val, R_val, d_val = train_val_split(X, R, dates, val_frac=0.2)\n",
        "\n",
        "data = {\n",
        "    \"X_train\": X_train, \"R_train\": R_train, \"dates_train\": d_train,\n",
        "    \"X_val\": X_val, \"R_val\": R_val, \"dates_val\": d_val,\n",
        "    \"feature_cols\": feature_cols, \"df\": df, \"n_assets\": 2, \"window_len\": WINDOW,\n",
        "}\n",
        "print(f\"Train windows: {X_train.shape[0]}, Val windows: {X_val.shape[0]}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train windows: 99, Val windows: 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-20T15:38:44.497542Z",
          "iopub.status.busy": "2026-02-20T15:38:44.497542Z",
          "iopub.status.idle": "2026-02-20T15:38:48.710973Z",
          "shell.execute_reply": "2026-02-20T15:38:48.710973Z"
        }
      },
      "source": [
        "# Train model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model, history = run_training(\n",
        "    data, device=device,\n",
        "    epochs=50, lr=1e-3, batch_size=32, patience=10,\n",
        "    model_type=\"gru\",\n",
        ")\n",
        "print(f\"Trained for {len(history)} epochs\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trained for 11 epochs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-20T15:38:48.713487Z",
          "iopub.status.busy": "2026-02-20T15:38:48.710973Z",
          "iopub.status.idle": "2026-02-20T15:38:48.730029Z",
          "shell.execute_reply": "2026-02-20T15:38:48.730029Z"
        }
      },
      "source": [
        "# Predict and export\n",
        "weights = predict_weights(model, data[\"X_val\"], device)\n",
        "stats = portfolio_stats(weights, data[\"R_val\"])\n",
        "\n",
        "out_dir = ROOT / \"results\"\n",
        "out_dir.mkdir(exist_ok=True)\n",
        "weights_path = out_dir / \"ipo_optimizer_weights.csv\"\n",
        "summary_path = out_dir / \"ipo_optimizer_summary.txt\"\n",
        "\n",
        "export_weights_csv(data[\"dates_val\"], weights, weights_path)\n",
        "export_summary(stats, weights, summary_path, R=data[\"R_val\"])\n",
        "print(f\"Exported weights to {weights_path}\")\n",
        "print(f\"Exported summary to {summary_path}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Exported weights to C:\\Users\\ocean\\anaconda_projects\\STAT-4830-OSO\\results\\ipo_optimizer_weights.csv\n",
            "Exported summary to C:\\Users\\ocean\\anaconda_projects\\STAT-4830-OSO\\results\\ipo_optimizer_summary.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2026-02-20T15:38:48.730029Z",
          "iopub.status.busy": "2026-02-20T15:38:48.730029Z",
          "iopub.status.idle": "2026-02-20T15:38:48.735559Z",
          "shell.execute_reply": "2026-02-20T15:38:48.735559Z"
        }
      },
      "source": [
        "# Policy interpretation\n",
        "avg_ipo = float(weights[:, 1].mean()) if weights.shape[1] >= 2 else 0.0\n",
        "scale = ipo_tilt_to_position_scale(avg_ipo)\n",
        "print(policy_rule(avg_ipo))\n",
        "print(f\"Suggested position scale for next IPO: {scale:.2f}\")\n",
        "print(f\"\\nMetrics: Sharpe={stats['sharpe_annualized']:.2f}, MaxDD={stats['max_drawdown']:.2%}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Consider increasing IPO exposure (model IPO weight > 20%).\n",
            "Suggested position scale for next IPO: 0.75\n",
            "\n",
            "Metrics: Sharpe=1.75, MaxDD=-3.07%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}